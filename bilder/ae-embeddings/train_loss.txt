epoch,train_loss,val_loss
0,8.018774032592773
1,3.051997184753418
2,2.8710005283355713
3,2.652346611022949
4,2.517204523086548
5,2.370086908340454
6,2.300297260284424
7,2.250896692276001
8,2.2021780014038086
9,2.1536741256713867
10,2.1143124103546143
11,2.0834362506866455
12,2.058666229248047
13,2.0374462604522705
14,2.0185232162475586
15,2.001749277114868
16,1.9869240522384644
17,1.973752737045288
18,1.962942123413086
19,1.9507298469543457
20,1.940879464149475
21,1.9306902885437012
22,1.9212660789489746
23,1.9117873907089233
24,1.9006413221359253
25,1.8903816938400269
26,1.8796796798706055
27,1.869371771812439
28,1.8591669797897339
29,1.849784016609192
30,1.841213345527649
31,1.8336259126663208
32,1.8270248174667358
33,1.8212409019470215
34,1.8161176443099976
35,1.8115389347076416
36,1.807389736175537
37,1.8034831285476685
38,1.7999451160430908
39,1.7966541051864624
40,1.793698787689209
41,1.7909505367279053
42,1.7883336544036865
43,1.785974144935608
44,1.7836635112762451
45,1.7815905809402466
46,1.7795807123184204
47,1.7776542901992798
48,1.775766134262085
49,1.7739962339401245
50,1.772226095199585
51,1.7706407308578491
52,1.768873929977417
53,1.7674202919006348
54,1.765769124031067
55,1.7643460035324097
