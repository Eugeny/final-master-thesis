\section{Background}
% taken from here https://pubs.acs.org/doi/full/10.1021/acsphotonics.2c00599?casa_token=_MabQ6pGe48AAAAA%3A3cKiQjee69lw88NnkGzeH3OiTfHFd71Z4NjOJWBpdIUMNYMERNJ6mu9UpaTOYhZT7K8nlmxvJf7EqLHD

%[TODO cite all the relevant references]    
The \textit{in silico} fluorescence labeling approach has proven to be very promising as a substitute to the manual cell staining processes. For example, the research of \cite{Christiansen_2018} did not only prove successful prediction of different cell stains with a variety of modalities and cell types, but it had also successfully determined cell viability. Nevertheless, the study is limited mainly to transmitted light (TL) z-stack imaging. This refers to the networks input being comprised of 3D images, which is not the case in this work, where only DIC imaging is used. \cite{Ounkomol_2018} too shows successful predictions of several organelles in bright-field TL 3D images using 3D convolutional neural networks. However, switching to 2D data did not yield adequate results for them. More recent studies like \cite{Ugawa_2021} provide an application of label-free fluorescence predicting already at the sorting stage, when a high-throughput system sorts cells individually. However, only a single-pixel detector is used by this study, meaning that it captures a wave rather than an image. Nonetheless one can recover an image from it with a ghost motion imaging technique (\cite{Bromberg_2009}), although this is computationally expensive (\cite{Sadao_2018}).
    %https://www.science.org/doi/10.1126/science.aan0096
    
    % [Boustany 2010 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3357207/]
There are two very interesting for this research recent studies by \cite{Cheng_2021} and \cite{Lachance_2020} that align very well with the processes in the project pipeline of Merck KGaA. Even though the former study manages to reach a state-of-the art performance on label-free fluorescence reconstruction, it uses reflectance images from oblique dark-field illumination as the input, which is a more specific cell imaging approach. Still, this input provides higher structural contrast in comparison to any transmission technique (\cite{Boustany_2010}). The latter study uses an easier imaging technique (DIC imaging) as an input, which shows great results even with low-resolution data. Both of these studies provide results based not only on training metrics, but also on performance of the models for metrics used in the practical biological evaluation. This is very important in the label-free fluorescence labeling research and was not present in research before \cite{Lachance_2020}.
    
All of the studies mentioned above, as well as this work rely on the premise that the input imaging type (here DIC) contains enough information to predict the fluorescence signal from it. This is a reasonable assumption because DIC, as well as bright-field and phase contrast imaging, are very often used for determining cell morphology (\cite{Kasprowicz_2017}).

This chapter provides a brief overview of the biological background needed to understand the process of cell line development and the role of fluorescent \textit{in silico} labeling of DIC cell images within. It also covers the fundamentals of deep and machine learning techniques used here including clustering and dimensionality reduction approaches, as well as the basics behind drift detection algorithms. At the end of the chapter, a brief summary of the microscopy image acquisition process used in the research is given.

    \subsection{Biology}
        \subsubsection{Cell line development process}
        \input{content/domain knowledge/cld theory.tex}
        \subsubsection{Improving the CHOZN\raisebox{1ex}{\small{\textregistered}} platform at Merck KGaA}
        \input{content/domain knowledge/cld in merck.tex}
    \subsection{Deep learning and machine learning basics}\label{subsection:dl}
        \subsubsection{Deep learning for computer vision}
            \input{content/domain knowledge/neural networks.tex}
        \subsubsection{Dimensionality reduction methods}
            \input{content/domain knowledge/dimentionality reduction.tex}
        \subsubsection{Clustering}
            \input{content/domain knowledge/clustering.tex}
    \subsection{Drift detection basics}
        Assume that during training labeled data comes from a distribution $p$, meaning $\{(x^{(1)}, y^{(1)}), ..., (x^{(n)}, y^{(n)})\} \sim p$ and during deployment unlabeled data comes from a distribution $q$, meaning $\{x^{(1)}\prime, ..., x^{(1)}\prime\} \sim q$. The goal of the drift detection is to determine if $q(x\prime)$ is the same data distribution as $p(x)$. Or, putting it more formally, determine which hypothesis holds: null-hypothesis $H_0$ and an alternative hypothesis $H_A$, where $H_0:p(x) = q(x)$ and $H_A:p(x) \neq q(x)$.
        Having samples from both distributions or representation of these samples in lower dimension, one can then choose a statistical hypothesis test to compare these distributions (\cite{Muandet_2017}).
        %\subsubsection{Drift detection vs. outliers detection}
        \subsubsection{Kernel methods and two-sample testing}
            \input{content/drift detection/kernel methods.tex}
        \subsubsection{Maximum mean discrepancy for drift detection}
            \input{content/drift detection/mmd.tex}
    \subsection{Imaging}
        \subsubsection{Digital imaging}
            \input{content/domain knowledge/digital imaging.tex}
        \subsubsection{Microscopy imaging}
            \input{content/domain knowledge/microscopy imaging.tex}
        \subsubsection{Local and global thresholding for image segmentation}
            \label{section:thresholding-theory}
            \input{content/domain knowledge/thresholding.tex}
        \subsubsection{Background removal algorithm}
            \label{section:background-removal}
            \input{content/domain knowledge/background removal.tex}