The drift detection of corrupted samples for the problem of the thesis has been performed using \textit{alibi-detect} open source python library, that focuses specifically on outlier, adversarial and drift detection algorithms \cite{alibi-detect}. Which implements statistical hypothesis testing algorithms for detecting drifts in data. 

It works in the following way, before observing some data, one can specify null-hypothesis $H_0$ and alternative hypothesis $H_1$ about generating process behind the data (its distribution for ex.) and also specify the test statistics $S(X)$ that are expected to be small under hypothesis $H_0$ and large under hypothesis $H_1$. Then during the observation of the new data test statistic value $S(X)$ is computed along with a probability $p = P(S(X)|H_0)$ which is called p-value. P-value is a probability that such an extreme value of test statistic could have been observed under the null-hypothesis. If this probability if below the established threshold $t$, then one assumes that data is drifted. If p-value is low, null-hypothesis will be refused. 

We have trained a drift detetion algorithm on UNet embeddings of not corrupted train data. For this experiment $5000$ embeddings were used of CHZN ans PHX phenotype from the nucleus dataset. After the drift detection algorithm was trained, we tested in on the test data, that was unseen by a model. Test dataset consists of 119 images, where from each image $5$ random crops were chosen. Since images have a high resolution, one can assume that one image itself represents a new input distribution, where crops taken from this image are its samples. Therefore we can detect whether one specific image has drifted or not feeding the crops from it into a drift detection algorithm. First, the algorithm was tested on not drifted data by using a test set of nucleus data. Its embeddings were fed into the algorithm and out of $119$ images $10$ werer recognized as the drifted ones. It means that algorithm's false positive rate is approximately $\frac{10}{119} \approx 0.08$. Figure \ref{fig:fn-rate} presents the results of drift detection for all artificial corruptions, more specifically alogorthm's false neagtive rate.
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{bilder/drift-detection/fn-rate.jpg}
		\caption{False negatives rate for drift detection on artificial corruptions}\label{fig:fn-rate}
	\end{center}
\end{figure}
One can see that the lower severity of a corruption is the higher a false negative rate becomes. When the corruption severity level if low (see \ref{fig:artificial-corruptions}) the predictions remain to have a high quality, therefore an end-user can still rely on the UNet. However, the stronger the corruption is, the stronger fluorescence prediction degenerates and as a result a drift detector alerts a user to the presence of a drift. Drift detector is more sensitive towards contrast changes rather then towards brightness changes. The most sensitive it is towards defoc blur corruption, which alings with the visual examinations, where it is clear that defocus blur has the most influence on fluorescence predictions.