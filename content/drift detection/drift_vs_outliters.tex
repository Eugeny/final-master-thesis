After developement phase when model training is finished, the model will be moved into a deployment or a production, where it is supposed to maintain an expected quality of predictions. However input data is not always a stable source of input. One should constantly maintain quality of predictions and do a regular check-ups for outliers as well as to alert an end-user about a drift in input data. Drift detection happens on raw data in absence of the ground truth labels and serves as a signal that the input data differs a lot from the data used for training, meaning that predictions became not reliable.

There is a significant difference between distinguishing drift of the whole source of data in comparison to detecting single outliers. In drift detection, one looks at the whole new input data as a distribution and checks if there is a significant shift in comparison to the data used during training.

There are two possible reactions after the drift is detected: alert the user that predictions became unreliable, and therefore she should consider expanding the dataset by adding more labeled data from a new drifted distribution in training or apply some different logic on the model outputs. When an outlier is detected, a model might request human assistance for some particular input, because this input is too unfamiliar to the model and possibly it won't give a good prediction on this one.

The goal of outlier detection is to decide on the single instances whether or not it is different from training data or unusual in some way or another. Outliers might appear both in training and prediction datasets.

Data drift and outlier detection can co-exist. It might be that the input is drifted, but there are no outliers, it might be that there are a lot of outliers, but the data was not drifted. (\cite{samuylova_2021}).

Important observation here is that the drift detector should be robust to outliers. The system should not send an alert as soon as it sees a suspicious sample due to the fact that outlier might be present in the original data distribution as well. But the alert should happen when there are many such samples. To compare original training data distribution and the new one from inputs different statistical tests like Kolmogorov-Smirnov, Chi-squared and etc. can used.

The need of maintaining drift detection or outlier detection depends on the costs on the errors. If the cost of a single error is too high, one should use an outlier detection, but when one needs a test to decide when to label new data - drift detection would be a better approach.

In summary, the drift detection is needed only when the meaningful shifts of the input data distribution from the training distribution need to be detected, whereas the outlier detector aims at finding unusual single instances in inputs. Here this is exactly the case, we train models assuming correct set up  of microscopy image acquisition, however changes in exposure, illumination, cell fixation procedure might alternate DIC imaging. In this case user has to be informed about it and choose afterwards whether he wants to add more data to the training set or not to use model's predictions.
